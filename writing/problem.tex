\chapter{Adversarial Derivations}
Here we look at the problem of crafting adversarial derivations for text.  Our goal is to alter a text sample in a small way which is not immediately noticeable to a reader, and yet causes a classifier to misclassify a particular sample.  This problem was originally studied in the context of image classification with convolutional neural networks.  This chapter considers a different kind of adversarial derivations/example.

\section{Adversarial Examples} 
\input{adversarial_examples}
\section{Word Embeddings}\label{sec:word_embeddings}
\input{word_embeddings}
\section{Adversarial Text Derivation}
\input{adversarial_text_derivation}

\chapter{Preliminary Results}
\section{Word Embedding Training}
\input{word_emb_results}
\section{RNN Training}
\input{preliminary_results}
\section{Stochastic Gradient Analysis}\label{sec:stochastic_gradient_analysis}
\input{stochastic_gradient_analysis}
